{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Classification] í˜€ëˆ„ë¥¼ ìœ„í•œ Maching Learning",
      "provenance": [],
      "collapsed_sections": [
        "whltSFA-WtX1",
        "uuDiyGB6XZQm"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYFuejL5sXMt"
      },
      "source": [
        "---\n",
        "# ğŸ“ Hyun's Code collection (Classification) \n",
        "---\n",
        "\n",
        "\n",
        "### <h3 align=\"right\">ğŸ¥‡ Authored by <strong>Hyun</strong></h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whltSFA-WtX1"
      },
      "source": [
        "# âœï¸ What is **Classification**?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziKN21X-nRmi"
      },
      "source": [
        "- Supervised Learningì˜ í•œ ì¢…ë¥˜\n",
        "- ê¸°ì¡´ ë°ì´í„°ì— ëŒ€í•œ íŠ¹ì§•ì„ í•™ìŠµí•œ ë’¤, ìƒˆë¡œìš´ ë°ì´í„°ê°€ ë“¤ì–´ì™”ì„ ë•Œ ê·¸ ë°ì´í„°ì˜ ì í•©í•œ ì§‘ë‹¨ì— ë”°ë¼ ë¶„ë¥˜í•´ì£¼ëŠ” ê²ƒ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuDiyGB6XZQm"
      },
      "source": [
        "# âœï¸ Classification Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvXHGMn6UOXk"
      },
      "source": [
        "## ğŸ” Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kyosm9OZw9qZ"
      },
      "source": [
        "- Sampleì´ íŠ¹ì • classì— ì†í•  í™•ë¥ ì„ ì¶”ì •í•˜ëŠ” ë° ì‚¬ìš©í•˜ëŠ” Regression\n",
        "- ì„ í˜• íšŒê·€ì™€ ê°™ì´ inputì— ëŒ€í•œ parameterë¥¼ ê³„ì‚°í•œ ë’¤, ê²°ê´ê°’ì˜ Logisticì„ ì¶œë ¥\n",
        "- Logistic Regressionì˜ í™•ë¥  ì¶”ì • <br>\n",
        "<br> $\\hat{p} = h_\\theta(x) = \\sigma(\\theta^T*x)$ <br>\n",
        "- [Logistic Regression numpy êµ¬í˜„](https://towardsdatascience.com/logistic-regression-from-scratch-with-numpy-da4cc3121ece)\n",
        "\n",
        "- Logistic functionì€ $\\sigma(t) = \\frac{1}{1+exp(-t)}$\n",
        "<br>\n",
        "\n",
        "<h3> Logistic functionì˜ cost function (log loss)  </h3>\n",
        "\n",
        "- $J(\\theta) = -\\frac{1}{m}\\sum_{(i=1)}^m[y^{(i)}log(\\hat{p}^{(i)})+(1-y^{(i)})log(1-\\hat{p}^{(i)})]$ <br>\n",
        "  <br>ì´ ë¹„ìš© í•¨ìˆ˜ì˜ ìµœì†Ÿê°’ì„ ê³„ì‚°í•˜ëŠ” í•´ëŠ” ì—†ìŒ.  \n",
        "  GDë¥¼ ì‚¬ìš©í•´ì„œ ì „ì—­ ìµœì†Ÿê°’ì„ ì°¾ì•„ì•¼ í•¨<br>\n",
        "<br>\n",
        "\n",
        "<h3> Logistic function cost functionì˜ í¸ë„í•¨ìˆ˜ </h3>\n",
        "\n",
        "- $\\frac{\\sigma}{\\sigma\\theta_j}J(\\theta) = \\frac{1}{m}\\sum_{(i=1)}^m(\\sigma(\\theta^T*x^{(i)})-y^{(i)})x_j^{(i)}$\n",
        "<br>\n",
        "- Logistic Regressionì˜ cost functionì€ ë³¼ë¡í•¨ìˆ˜ì—¬ì„œ GDë¥¼ ì¨ë„ ì§€ì—­ ìµœì†Ÿê°’ì— ê°‡íˆì§€ ì•ŠëŠ”ë‹¤.\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PToCO4fWVl18"
      },
      "source": [
        "### ğŸ“” Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rlc5Mxl1mgmq"
      },
      "source": [
        "import statsmodels.api as sm\n",
        "model = sm.Logit(y_train, X_train)\n",
        "results = model.fit()\n",
        "results.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWb1GnWYmgPP"
      },
      "source": [
        "  # Logistic regression ì—ì‹œ\n",
        "# ë¨¼ì € ë°ì´í„°ë¥¼ ë°˜ì‘ë³€ì¸ê³¼ ì˜ˆì¸¡ë³€ì¸ìœ¼ë¡œ ë¶„ë¦¬í•˜ê¸°\n",
        "Y = (df['Status'] == 'Developed').astype(np.int) #'Developed'ë©´ 1, ì•„ë‹ˆë©´ 0ìœ¼ë¡œ\n",
        "X = df.drop('Status', axis=1)\n",
        "\n",
        "# ì˜ˆì¸¡ë³€ì¸ê³¼ ë°˜ì‘ë³€ì¸ì„ train setê³¼ test setìœ¼ë¡œ ë¶„ë¦¬í•´ ì¤ë‹ˆë‹¤.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# 1. ë¨¼ì € ëª¨ë¸ì„ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤.\n",
        "logReg = LogisticRegression()\n",
        "\n",
        "# 2. ëª¨ë¸ ì í•©ì‹œí‚µë‹ˆë‹¤.\n",
        "logReg.fit(X_train, y_train)\n",
        "\n",
        "# 3. íŠ¸ë ˆì´ë‹ì…‹ê³¼ í…ŒìŠ¤íŠ¸ì…‹ì—ì„œì˜ ì„±ëŠ¥ì„ í™•ì¸í•©ë‹ˆë‹¤. (ì´ ê²½ìš° ê²°ì •ê³„ìˆ˜ R^2)\n",
        "print('Training R^2:', logReg.score(X_train, y_train))\n",
        "print('Test R^2: ', logReg.score(X_test, y_test))\n",
        "\n",
        "# ëª¨ë¸ë¡œë¶€í„° ë°˜ì‘ì„ ì˜ˆì¸¡í•˜ê³  accuracy, f1-score, confusion matrixë¥¼ êµ¬í•´ë´…ì‹œë‹¤.\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "y_pred = logReg.predict(X_test)\n",
        "print(\"Accuracy: %.2f\" %accuracy_score(y_test, y_pred))\n",
        "print(\"F1 score: %.2f\" %f1_score(y_test, y_pred))\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKTkFrM4Xfks"
      },
      "source": [
        "## ğŸ” Linear Support Vector Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0uA9qcpf_pY"
      },
      "source": [
        "\n",
        "- SVMëŠ” í´ë˜ìŠ¤ ì‚¬ì´ì— í­ì´ ê°€ì¥ ë„“ì€ ë„ë¡œë¥¼ ì°¾ëŠ” ê²ƒì´ë‹¤! ê·¸ë˜ì•¼ ìƒˆë¡œìš´ ìƒ˜í”Œì— ëŒ€í•´ì„œë„ ì˜ ì‘ë™!\n",
        "- Large Margin Classificationì´ë¼ê³ ë„ ë¶€ë¥¸ë‹¤.\n",
        "\n",
        "- SVCëŠ” ê¸°ë³¸ê°’ì—ì„œ í´ë˜ìŠ¤ í™•ë¥ ì„ ì œê³µí•˜ì§€ ì•ŠìŒ. ê·¸ë ‡ê¸°ì— probability ë§¤ê°œë³€ìˆ˜ë¥¼ Trueë¡œ ì§€ì •í•´ì¤˜ì•¼ í•¨!\n",
        "- ê·¸ëŸ¬ë©´ cross-validationì„ ì“°ê¸° ë•Œë¬¸ì— ëŠë ¤ì§€ì§€ë§Œ predict_proba() ë©”ì†Œë“œ ì‚¬ìš© ê°€ëŠ¥  <br>\n",
        " \n",
        "- SVMì€ íŠ¹ì„±ì˜ scaleì— ë¯¼ê°\n",
        "\n",
        "> Hard margin Classification\n",
        "- ë¬¸ì œ\n",
        "  1. ë°ì´í„°ê°€ ì„ í˜•ì ìœ¼ë¡œ êµ¬ë¶„ë˜ì–´ì•¼ ì˜ ì‘ë™\n",
        "  2. ì´ìƒì¹˜ì— ë¯¼ê°\n",
        "\n",
        "> Soft Margin Classification\n",
        "- ë„ë¡œì˜ í­ì€ ê°€ëŠ¥í•œ ë„“ê²Œ í•˜ëŠ” ê²ƒ & ë§ˆì§„ ì˜¤ë¥˜ ì‚¬ì´ì— ê· í˜•ì„ ì¡ì€ ëª¨ë¸\n",
        "- SVM ëª¨ë¸ì˜ C hyperparameterë¡œ ê· í˜•ì„ ì¡°ì ˆ ê°€ëŠ¥í•˜ë‹¤!  \n",
        "  Cê°€ ë‚®ì„ ìˆ˜ë¡ ë” ì¼ë°˜í™”ëœ ëª¨ë¸ì„ ë§Œë“¤ ìˆ˜ ìˆë‹¤. (p.203)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HQFxPX7XtF2"
      },
      "source": [
        "### ğŸ“” Basic Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H3daCvIXvWE"
      },
      "source": [
        "- **LinearSVC( C=1, loss='hinge')**: ê¸°ë³¸ learner SVC ëª¨ë¸"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM75jOOwXxgX"
      },
      "source": [
        "### ğŸ“” Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfLegX505h-4"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "model = LinearSVC(C=1, loss='hinge')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH1hWbzTXhoH"
      },
      "source": [
        "## ğŸ” Non-linear Support Vector Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN7vsBr66CMs"
      },
      "source": [
        "- ë¹„ì„ í˜• ë°ì´í„°ì…‹ì„ ë‹¤ë£¨ëŠ” í•œ ê°€ì§€ ë°©ë²•ì€ ë‹¤í•­ íŠ¹ì„± ë“±ì„ ì¶”ê°€í•˜ëŠ” ê²ƒ\n",
        "- ì•„ë‹ˆë©´ ì»¤ë„ íŠ¸ë¦­ìœ¼ë¡œ í›ˆë ¨ê°€ëŠ¥. ì»¤ë„ íŠ¸ë¦­ì€ ì‹¤ì œë¡œëŠ” íŠ¹ì„±ì„ ì¶”ê°€í•˜ì§€ ì•Šìœ¼ë©´ì„œ ë‹¤í•­ì‹ íŠ¹ì„±ì„ ë§ì´ ì¶”ê°€í•œ ê²ƒê³¼ ê°™ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŒ\n",
        "- í˜¹ì€ ìœ ì‚¬ë„ í•¨ìˆ˜ë¡œ ê³„ì‚°í•œ íŠ¹ì„±ì„ ì¶”ê°€í•  ìˆ˜ë„ ìˆë‹¤. í›ˆë ¨ ì„¸íŠ¸ê°€ ë„ˆë¬´ í¬ì§€ ì•Šë‹¤ë©´ ê°€ìš°ì‹œì•ˆ RBF ì»¤ë„ì„ ì‹œë„í•´ë„ ì¢‹ë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2tt2wx2YY6s"
      },
      "source": [
        "### ğŸ“” Basic Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXHLsnqJYd23"
      },
      "source": [
        "- **LinearSVC( C = 1, kernel = \"linear\", loss = 'hinge' )**: ê¸°ë³¸ learner SVC ëª¨ë¸\n",
        "- **LinearSVC( C = 5, kernel = \"poly\", degree = 3, coef0 = 1 )**: ë‹¤í•­ kernelì´ ì¶”ê°€ëœ SVM ëª¨ë¸\n",
        "  - kernel: polyë¡œ ì„¤ì •í•˜ë©´ ë‹¤í•­ì‹ ì»¤ë„ì„ ì‚¬ìš©í•´ SVM ë¶„ë¥˜ê¸°ë¥¼ í›ˆë ¨ì‹œí‚´\n",
        "  - coef0: ëª¨ë¸ì´ ë†’ì€ ì°¨ìˆ˜ì™€ ë‚®ì€ ì°¨ìˆ˜ì— ì–¼ë§ˆë‚˜ ì˜í–¥ì„ ë°›ì„ì§€ ì¡°ì ˆí•¨\n",
        "- **LinearSVC( C = 0.001, kernel = \"rbf\", gamma = 5 )**: ê¸°ë³¸ learner SVC ëª¨ë¸\n",
        "  - gamma: gammaë¥¼ ì¦ê°€ì‹œí‚¤ë©´ ì¢… ëª¨ì–‘ ê·¸ë˜í”„ê°€ ì»¤ì ¸ ê° ìƒ˜í”Œì˜ ì˜í–¥ ë²”ìœ„ê°€ ì‘ì•„ì§. ê·œì œ ì—­í• ì„ í•¨. Overfittingì´ë©´ ê°ì†Œì‹œí‚¤ê³  Underfittingì´ë©´ ì¦ê°€ì‹œì¼œì•¼ í•¨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bJS_3BEYY2Z"
      },
      "source": [
        "### ğŸ“” Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btAzJ_Ja7gaS"
      },
      "source": [
        "from sklearn.datasets import make_moons\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "polynomial_svm_clf = Pipeline([\n",
        "        (\"poly_features\", PolynomialFeatures(degree=3)),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"svm_clf\", LinearSVC(C=10, loss=\"hinge\", max_iter=2000, random_state=42))\n",
        "    ])\n",
        "\n",
        "polynomial_svm_clf.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv8Lzj608B-g"
      },
      "source": [
        "# ê·¸ë¦¼ìœ¼ë¡œ í™•ì¸í•˜ê¸°\n",
        "def plot_predictions(clf, axes):\n",
        "    x0s = np.linspace(axes[0], axes[1], 100)\n",
        "    x1s = np.linspace(axes[2], axes[3], 100)\n",
        "    x0, x1 = np.meshgrid(x0s, x1s)\n",
        "    X = np.c_[x0.ravel(), x1.ravel()]\n",
        "    y_pred = clf.predict(X).reshape(x0.shape)\n",
        "    y_decision = clf.decision_function(X).reshape(x0.shape)\n",
        "    plt.contourf(x0, x1, y_pred, cmap=plt.cm.brg, alpha=0.2)\n",
        "    plt.contourf(x0, x1, y_decision, cmap=plt.cm.brg, alpha=0.1)\n",
        "\n",
        "plot_predictions(polynomial_svm_clf, [-1.5, 2.5, -1, 1.5])\n",
        "plot_dataset(X, y, [-1.5, 2.5, -1, 1.5])\n",
        "\n",
        "save_fig(\"moons_polynomial_svc_plot\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLxLjwhZXJSB"
      },
      "source": [
        "## ğŸ” SGD Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0gRZo1oYipG"
      },
      "source": [
        "### ğŸ“” Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUZD9-BvnO3E"
      },
      "source": [
        "# SGD Classifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd_clf=SGDClassifier(random_state=42) \n",
        "'''\n",
        "GDClassifierëŠ” randomnessì— ê¸°ë°˜í•˜ê¸° ë•Œë¬¸ì—, \n",
        "ê³ ì • ê°’ì„ ì •í•˜ê³  ì‹¶ë‹¤ë©´, random_state parameterë¥¼ ì“°ì.\n",
        "'''\n",
        "sgd_clf.fit(X_train,y_train)\n",
        "\n",
        "sgd_clf.predict(X_test)\n",
        "\n",
        "y_pred = sgd_clf.predict(X_test)\n",
        "\n",
        "f1_score(y_test,y_pred, average='micro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sisl4ELKXlvI"
      },
      "source": [
        "## ğŸ” XGboost Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdq9oYxmYjDI"
      },
      "source": [
        "### ğŸ“” Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z84bRmfnQQG"
      },
      "source": [
        "# Xgboost Classifier\n",
        "from xgboost import XGBClassifier, plot_importance\n",
        "\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "model.predict(X_test)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_score(y_test,y_pred, average='weighted')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}