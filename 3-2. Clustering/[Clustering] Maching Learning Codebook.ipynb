{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Clustering] í˜€ëˆ„ë¥¼ ìœ„í•œ Maching Learning",
      "provenance": [],
      "collapsed_sections": [
        "WRc4iW_KhzIM",
        "0CiEbrGRh2dM",
        "wGGUGYR9y4LI",
        "Qsda25F5fVaX",
        "SAAHvcqYy4PZ",
        "xCgGkm0Sih6N",
        "DvZ5Q-fky4TV",
        "Q_1sV2q-iitk",
        "3p0Lc8RFy4XJ",
        "Q4GE559ly4Zw"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYFuejL5sXMt"
      },
      "source": [
        "---\n",
        "# ğŸ“ Hyun's Code collection (Clustering) \n",
        "---\n",
        "\n",
        "\n",
        "### <h3 align=\"right\">ğŸ¥‡ Authored by <strong>Hyun</strong></h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRc4iW_KhzIM"
      },
      "source": [
        "# âœï¸ What is **Clustering**?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZdmhewVhldP"
      },
      "source": [
        "- ëŒ€í‘œì ì¸ ë¹„ì§€ë„í•™ìŠµ. ì§‘ë‹¨ì´ ì£¼ì–´ì§€ì§€ ì•Šì€ ë°ì´í„°ì— êµ°ì§‘ì„ ë¶€ì—¬í•´ì£¼ëŠ” ê²ƒ\n",
        "- êµ°ì§‘ ë‚´ì˜ ë¶„ì‚°ì„ ìµœì†Œí™”í•˜ê³  êµ°ì§‘ ê°„ì˜ ë¶„ì‚°ì„ ìµœëŒ€í•œ ìœ ì‚¬í•œ ê°œì²´ë¡œ ë¬¶ì–´ì£¼ëŠ” ê²ƒ!\n",
        "- ë°©ë²•ì€ í¬ê²Œ 5ê°œ  \n",
        "  - K-means clustering\n",
        "  - Hierarchical clustering\n",
        "  - DBSCAN\n",
        "  - Gaussian Muxture model (GMM)\n",
        "  - KNN clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CiEbrGRh2dM"
      },
      "source": [
        "# âœï¸ Clustering Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGGUGYR9y4LI"
      },
      "source": [
        "## ğŸ” K-means clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izjS1NuHiplI"
      },
      "source": [
        "- Centroid ë°©ì‹ì„ í™œìš©í•˜ì—¬ ì£¼ì–´ì§„ ê°¯ìˆ˜ì— ë§ê²Œ êµ°ì§‘ì„ ë‚˜ëˆ ì¤€ë‹¤.\n",
        "- ê° clusterì™€ì˜ ìœ í´ë¦¬ë””ì•ˆ ê±°ë¦¬ ì°¨ì´ë“¤ì„ êµ¬í•˜ê³  ê·¸ ê°’ë“¤ì˜ ë¶„ì‚°ì„ ìµœì†Œí™”í•˜ëŠ” ë°©ì‹\n",
        "- K-meansì˜ í•œê³„\n",
        " 1. sub-optimal solutionì„ í”¼í•˜ê¸° ìœ„í•´ ì—¬ëŸ¬ë²ˆ ì‹œí–‰í•´ì•¼ í•¨\n",
        " 2. Cluster ê°¯ìˆ˜ë¥¼ ì§ì ‘ ì§€ì •í•´ì•¼ í•˜ë©°, Outlierì— ì·¨ì•½í•˜ë‹¤ (ìœ í´ë¦¬ë””ì•ˆ ê±°ë¦¬ì—¬ì„œ)\n",
        " 3. Varying sizes, Different densities, Non-spherical shapesì˜ ê²½ìš°ì— ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFRUceb0itOz"
      },
      "source": [
        "<h3> ğŸ“” K-Means Algorithm  </h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNmGrnh5iph1"
      },
      "source": [
        "1. ë°ì´í„° ì§‘í•©ì˜ Objects ì¤‘ì—ì„œ ì„¤ì •í•œ Clusterì˜ ê°œìˆ˜ì¸ kê°œì˜ Centroidë¥¼ ì„ìœ¼ë¡œ ì„ íƒí•œë‹¤.  \n",
        "2. ì§‘í•© ì†ì˜ ëª¨ë“  Objectsì™€ ì•ì„œ ì„ íƒí•œ Centroidì™€ì˜ ê±°ë¦¬ë¥¼ ê°ê° êµ¬í•˜ê³ , ê°€ì¥ ê°€ê¹Œìš´ Centroidê°€ ì†í•˜ëŠ” Clusterì— Objectsë¥¼ í• ë‹¹í•œë‹¤.  \n",
        "3. ê°™ì€ Clusterë¡œ í• ë‹¹ëœ Objectsë“¤ì˜ ì¤‘ì‹¬ì ì„ ì°¾ê³ , ê·¸ ì ì„ ìƒˆë¡œìš´ Centroidë¡œ ì„¤ì •í•œë‹¤.  \n",
        "4. Centroidì˜ ë³€í™”ê°€ ì—†ì„ ë•Œê¹Œì§€ 2-3 ê³¼ì •ì„ ë°˜ë³µí•œë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rqfvaQ0iz5r"
      },
      "source": [
        "<h3> ğŸ“” K-means++ Algorithm </h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KegDkKLCiz2f"
      },
      "source": [
        "1. ì²« initial point c1ì„ ì„ì˜ë¡œ ì„ íƒí•œë‹¤.  \n",
        "2. ì´í›„ì˜ initial point ctëŠ” ì´ì „ì— ì„ íƒí•œ ct-1ê³¼ì˜ ê±°ë¦¬ì¸ d(ct-1, ct)ê°€ í° ì ì´ ë†’ì€ í™•ë¥ ë¡œ ì„ íƒë˜ë„ë¡ ìƒ˜í”Œë§ í™•ë¥  ë¶„í¬ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì¡°ì ˆí•˜ê³ , ì´ ë¶„í¬ì— ë”°ë¼ í•˜ë‚˜ì˜ ì ì„ ì„ íƒí•œë‹¤.\n",
        "3. k ê°œì˜ initial pointsë¥¼ ì„ íƒí•  ë•Œê¹Œì§€ step 2ë¥¼ ë°˜ë³µí•œë‹¤.\n",
        "ìƒ˜í”Œë§ í™•ë¥  ë¶„í¬ë¥¼ ì‚¬ìš©í•¨ì— ë”°ë¼ ctëŠ” ì´ì „ì— ì„ íƒí•œ ì  ct-1ê³¼ ê±°ë¦¬ê°€ ë¨¼ ì ì¼ ê°€ëŠ¥ì„±ì´ ë†’ë‹¤. í•œ ê°€ì§€ ë‹¨ì ì´ ìˆë‹¤ë©´, ct-1ê³¼ ct+1ì´ ë¹„ìŠ·í•  ìˆ˜ë„ ìˆë‹¤. (â€»Ball cutì´ë¼ëŠ” ë°©ë²•ìœ¼ë¡œ í•´ê²° ê°€ëŠ¥.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbiWdiu2izym"
      },
      "source": [
        "<h3> ğŸ“” ì„±ëŠ¥í‰ê°€ </h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZB1U5aHipeZ"
      },
      "source": [
        "- K-meansëŠ” inertia ê°’ìœ¼ë¡œ ì„±ëŠ¥ì„ í‰ê°€í•œë‹¤.\n",
        "- inertiaëŠ” K-Means Clusteringìœ¼ë¡œ ê³„ì‚°ëœ SSE ê°’\n",
        "- kmeans.inertia_ ì„ í†µí•´ ê°’ì„ êµ¬í•  ìˆ˜ ìˆìœ¼ë©°, ì‘ì„ìˆ˜ë¡ ì¢‹ë‹¤.\n",
        "- kmeans.score(X) ë¥¼ í†µí•´ì„œë„ ì„±ëŠ¥ íŒŒì•…ì´ ê°€ëŠ¥í•œë°, ì´ ê°’ì€ inertiaì˜ ìŒì˜ ê°’ì´ë‹¤. (ì¼ë°˜ì ìœ¼ë¡œ í´ìˆ˜ë¡ ì¢‹ë‹¤ëŠ” **\"greater is better\"** rule ë•Œë¬¸ì— ì‚¬ìš©ëœë‹¤.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VA16UhXojB3p"
      },
      "source": [
        "<h3> ğŸ“” kê°œì˜ ì ì ˆí•œ êµ°ì§‘ ìˆ˜ ì°¾ëŠ” ë°©ë²• </h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz6WaFiZjB02"
      },
      "source": [
        "1. Rule of thumb </b>  \n",
        "ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•ìœ¼ë¡œ, ë°ì´í„°ì˜ ìˆ˜ê°€ nì´ë¼ê³  í•  ë•Œ, í•„ìš”í•œ Clusterì˜ ìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°í•  ìˆ˜ ìˆë‹¤.  \n",
        "$$k â‰ˆ \\sqrt{n / 2}$$\n",
        "\n",
        "2. Elbow method \n",
        "Clusterì˜ ìˆ˜ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ëŠ˜ë ¤ê°€ë©´ì„œ ê²°ê³¼ë¥¼ ëª¨ë‹ˆí„°ë§ í•œë‹¤. ë§Œì•½ í•˜ë‚˜ì˜ í´ëŸ¬ìŠ¤í„°ë¥¼ ì¶”ê°€í–ˆì„ ë•Œ, ì´ì „ë³´ë‹¤ í›¨ì”¬ ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ë‚˜íƒ€ë‚´ì§€ ì•ŠëŠ”ë‹¤ë©´, ì´ì „ì˜ í´ëŸ¬ìŠ¤í„°ì˜ ìˆ˜ë¥¼ êµ¬í•˜ê³ ì í•˜ëŠ” í´ëŸ¬ìŠ¤í„°ì˜ ìˆ˜ë¡œ ê²°ì •í•œë‹¤.  \n",
        "\n",
        "3. Silhouette Method  \n",
        "  - Clusteringì˜ í’ˆì§ˆì„ ì •ëŸ‰ì ìœ¼ë¡œ ê³„ì‚°í•´ì£¼ëŠ” ë°©ë²•ì´ë‹¤. ië²ˆì§¸ ë°ì´í„° x(i)ì— ëŒ€í•œ ì‹¤ë£¨ì—£ ê³„ìˆ˜ s(i) ê°’ì€ ì•„ë˜ì˜ ì‹ìœ¼ë¡œ ì •ì˜ \n",
        " ![silhouette formula](https://static.packt-cdn.com/products/9781788996402/graphics/739fcde8-e95d-4ab2-a2f2-f3fc804a8872.png) \n",
        "  - a(i)ëŠ” Cluster ë‚´ë¶€ì˜ ë°ì´í„° ì‘ì§‘ë„(cohesion)ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê°’ìœ¼ë¡œ, x(i)ì™€ ë™ì¼í•œ Cluster ë‚´ì˜ ë‚˜ë¨¸ì§€ ë°ì´í„°ë“¤ê³¼ì˜ í‰ê· ê±°ë¦¬ì´ë‹¤.\n",
        "  - b(i)ëŠ” Cluster ê°„ì˜ ë¶„ë¦¬ë„(separation)ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê°’ìœ¼ë¡œ, ë°ì´í„° x(i)ì™€ ê°€ì¥ ê°€ê¹Œìš´ í´ëŸ¬ìŠ¤í„° ë‚´ì˜ ëª¨ë“  ë°ì´í„°ë“¤ê³¼ì˜ í‰ê· ê±°ë¦¬ì´ë‹¤.\n",
        "  - ì‹¤ë£¨ì—£ ê³„ìˆ˜ ê°’ì€ 1ì— ê°€ê¹Œìš¸ ìˆ˜ë¡ ìµœì í™”ëœ Clusteringì´ë‹¤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qsda25F5fVaX"
      },
      "source": [
        "### ğŸ“” Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StUbiWNhg-Zs"
      },
      "source": [
        "# K-means in image segmentation ì˜ˆì‹œ\n",
        "img = plt.imread('./img/img_seg_1.jpg')\n",
        "\n",
        "X = img.reshape(-1,3)\n",
        "\n",
        "segmented_imgs = []\n",
        "n_colors = (20, 15, 10, 5, 3)\n",
        "for n_clusters in n_colors:\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(X)\n",
        "    segmented_img = kmeans.cluster_centers_[kmeans.labels_]\n",
        "    segmented_imgs.append(segmented_img.reshape(img.shape))\n",
        "    \n",
        "    \n",
        "plt.figure(figsize=(10,8))\n",
        "plt.subplots_adjust(wspace=0.05, hspace=0.1)\n",
        "\n",
        "plt.subplot(231)\n",
        "plt.imshow(img)\n",
        "plt.title(\"Original image\")\n",
        "plt.axis('off')\n",
        "\n",
        "for idx, n_clusters in enumerate(n_colors):\n",
        "    plt.subplot(232 + idx)\n",
        "    plt.imshow(segmented_imgs[idx])\n",
        "    plt.title(\"{} colors\".format(n_clusters))\n",
        "    plt.axis('off')\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X43CXP1RQJn1"
      },
      "source": [
        "# Silhouette ë¶„ì„ ì—ì‹œ\n",
        "range_n_clusters = range(2,17)\n",
        "\n",
        "for n_clusters in range_n_clusters:\n",
        "    clusterer = KMeans(n_clusters=n_clusters)\n",
        "    preds = clusterer.fit_predict(df_senator_with_party[['x','y']])\n",
        "    centers = clusterer.cluster_centers_\n",
        "\n",
        "    score = silhouette_score(df_senator_with_party[['x','y']], preds)\n",
        "    print(\"For n_clusters = {}, silhouette score is {}\".format(n_clusters, round(score, 4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v86PdPAdg-kR"
      },
      "source": [
        "# Silhouette ë¶„ì„ ì˜ˆì‹œ\n",
        "from __future__ import print_function\n",
        "\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import numpy as np\n",
        "\n",
        "X, y = make_blobs(n_samples = 500, n_features = 2, centers = 4, cluster_std = 1.0,\n",
        "                  center_box = (-10.0, 10.0), shuffle = True, random_state = 1)\n",
        "\n",
        "range_n_clusters = [2, 3, 4, 5, 6]\n",
        "\n",
        "for n_clusters in range_n_clusters:\n",
        "    fig, (ax1, ax2) = plt. subplots(1, 2)\n",
        "    fig.set_size_inches(18, 7)\n",
        "    \n",
        "    ax1.set_xlim([-0.1, 1]) # ì‹¤ë£¨ì—£ ê³„ìˆ˜ ë²”ìœ„ ì§€ì •\n",
        "    ax1.set_ylim([0, len(X) + (n_clusters+1) * 10]) # ì‹¤ë£¨ì—£ í´ëŸ¬ìŠ¤í„° ì‚¬ì´ì˜ ê³µê°„ ë§Œë“¤ê¸°\n",
        "    \n",
        "    kmeans__ = KMeans(n_clusters = n_clusters, random_state = 10)\n",
        "    kmeans__labels = kmeans__.fit_predict(X)\n",
        "    \n",
        "    silhouette_avg = silhouette_score(X, kmeans__labels)\n",
        "    print(\"For n_clusters =\", n_clusters, \"The average silhouette_score is :\", silhouette_avg)\n",
        "    \n",
        "    sample_silhouette_values = silhouette_samples(X, kmeans__labels)\n",
        "    \n",
        "    y_lower = 10\n",
        "    \n",
        "    for i in range(n_clusters):\n",
        "        ith_cluster_silhouette_values = \\\n",
        "            sample_silhouette_values[kmeans__labels == i]\n",
        "            \n",
        "        ith_cluster_silhouette_values.sort()\n",
        "            \n",
        "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
        "        y_upper = y_lower + size_cluster_i\n",
        "            \n",
        "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
        "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
        "                          0, ith_cluster_silhouette_values,\n",
        "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
        "\n",
        "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i)) # silhouette plots ê°ê° label ë¶™ì´ê¸°\n",
        "\n",
        "        y_lower = y_upper + 10  # ë‹¤ìŒ plotì„ ê·¸ë¦¬ê¸°ìœ„í•´ y_lower ìƒˆë¡œ ê°±ì‹ \n",
        "        \n",
        "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
        "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
        "    ax1.set_ylabel(\"Cluster label\")\n",
        "    \n",
        "    ax1.axvline(x = silhouette_avg, color = \"r\", linestyle=\"--\") # silhouette score í‰ê· ê°’ ê·¸ë¦¬ê¸°\n",
        "    \n",
        "\n",
        "    # Cluster ë³´ì—¬ì£¼ê¸° (2nd plot)\n",
        "    colors = cm.nipy_spectral(kmeans__labels.astype(float) / n_clusters)\n",
        "    ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n",
        "                c=colors, edgecolor='k')\n",
        "\n",
        "    kmeans__centers = kmeans__.cluster_centers_ # cluster labeling\n",
        "    ax2.scatter(kmeans__centers[:, 0], kmeans__centers[:, 1], marker='o',\n",
        "                c=\"white\", alpha=1, s=200, edgecolor='k') # centroid circle design\n",
        "\n",
        "    for i, c in enumerate(kmeans__centers):\n",
        "        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
        "                    s=50, edgecolor='k')\n",
        "\n",
        "    ax2.set_title(\"The visualization of the clustered data.\")\n",
        "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
        "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
        "\n",
        "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
        "                  \"with n_clusters = %d\" % n_clusters),\n",
        "                 fontsize=14, fontweight='bold')\n",
        "\n",
        "    plt.show()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5R9OHf1g-3B"
      },
      "source": [
        "# Elbow ì˜ˆì‹œ\n",
        "X, y = make_blobs(n_samples = 150, n_features = 2, centers = 3, cluster_std= 0.50, shuffle = True, random_state=0)\n",
        "\n",
        "def elbow(X):\n",
        "    sse = []\n",
        "    for i in range(1,11):\n",
        "        kmeans_elbow = KMeans(n_clusters = i, init = 'k-means++', random_state = 0)\n",
        "        kmeans_elbow.fit(X)\n",
        "        sse.append(kmeans_elbow.inertia_)\n",
        "        \n",
        "    plt.plot(range(1,11), sse, 'o-')\n",
        "    plt.xlabel('Number of Clusters')\n",
        "    plt.ylabel('SSE(inertia)')\n",
        "    plt.xticks(np.arange(11))\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "elbow(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsQJZOzVg-8E"
      },
      "source": [
        "# Kmeans ì˜ˆì‹œ (random, k-means ++)\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "X, y = make_blobs(n_samples = 1000, centers = 4, cluster_std= 0.60, random_state=0)\n",
        "\n",
        "k = 6\n",
        "kmeans_random = KMeans(n_clusters = k, init = 'random', max_iter = 3)\n",
        "kmeans_plus = KMeans(n_clusters = k, init = 'k-means++', max_iter = 3)\n",
        "kmeans_random.fit(X)\n",
        "kmeans_plus.fit(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIc5Usg-g-_-"
      },
      "source": [
        "# ì„±ëŠ¥í‰ê°€ ì˜ˆì‹œ\n",
        "print(\"inertia = {:5.2f}, score = {:5.2f}\".format(kmeans.inertia_, kmeans.score(X)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrGlJVzrg_Di"
      },
      "source": [
        "# Kmeans ì˜ˆì‹œ1\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "X = np.array([[1, 2], [1, 4], [1, 0],\n",
        "               [10, 2], [10, 4], [10, 0]])\n",
        "\n",
        "kmeans = KMeans(n_clusters=2, random_state=0).fit(X)  # 2ê°œì˜ clusterë¡œ ë‚˜ëˆ ë¼\n",
        "\n",
        "kmeans.labels_    # ê° ë°ì´í„°ì— ëŒ€í•œ í´ëŸ¬ìŠ¤í„° ê²°ê³¼ë¬¼\n",
        "# array([1, 1, 1, 0, 0, 0], dtype=int32)\n",
        "\n",
        "kmeans.predict([[0, 0], [12, 3]])\n",
        "# array([1, 0], dtype=int32)\n",
        "\n",
        "kmeans.cluster_centers_\n",
        "#array([[10.,  2.], [ 1.,  2.]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwYBaKX5hMGs"
      },
      "source": [
        "# Kmeans ì˜ˆì‹œ2\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "df = pd.DataFrame([\n",
        "        [2, 1],\n",
        "        [3, 2],\n",
        "        [3, 4],\n",
        "        [5, 5],\n",
        "        [7, 5],\n",
        "        [2, 5],\n",
        "        [8, 9],\n",
        "        [9, 10],\n",
        "        [6, 12]\n",
        "    ], columns=['hour', 'attendance'])\n",
        "\n",
        "model = KMeans(n_clusters=3)\n",
        "\n",
        "model.fit(df)\n",
        "\n",
        "y_predict = model.fit_predict(df)\n",
        "print(y_predict) \n",
        "#[0 0 0 2 2 0 1 1 1]\n",
        "\n",
        "df['cluster'] = y_predict\n",
        "print(df)\n",
        "'''\n",
        "   hour  attendance  cluster\n",
        "0     2           1        0\n",
        "1     3           2        0\n",
        "2     3           4        0\n",
        "3     5           5        2\n",
        "4     7           5        2\n",
        "5     2           5        0\n",
        "6     8           9        1\n",
        "7     9          10        1\n",
        "8     6          12        1\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf_E3Obv-jsc"
      },
      "source": [
        "# Clustering í›„ clusterë³„ íŠ¹ì§• ê·¸ë˜í”„ë¡œ ë‚˜íƒ€ë‚´ê¸°\n",
        "plt.rcParams['axes.unicode_minus'] = False #ê·¸ë˜í”„ì—ì„œ - í°íŠ¸ ê¹¨ì§€ëŠ”ê±° ë°©ì§€\n",
        "fontlocation=\"C:/Windows/Fonts/HMFMPYUN.TTF\"\n",
        "font_name = font_manager.FontProperties(fname=fontlocation).get_name()\n",
        "plt.rc('font', family=font_name)\n",
        "\n",
        "tempDf.iloc[:,1:].transpose().plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAAHvcqYy4PZ"
      },
      "source": [
        "## ğŸ” Hierarchical clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qhk0YecehMLv"
      },
      "source": [
        "- Connectivity methodë¥¼ í™œìš©í•˜ì—¬ Bottom-Up ë°©ì‹ìœ¼ë¡œ ë´ë“œë¡œê·¸ë¨ì„ ê·¸ë ¤ì£¼ê³  ê±°ê¸°ì„œ ì£¼ê´€ì— ì˜í•´ì„œ ì ì ˆí•œ êµ°ì§‘ ê°¯ìˆ˜ë¥¼ ì°¾ëŠ” ë°©ì‹. í° ë°ì´í„°ì—ëŠ” ì ìš©í•˜ê¸° í˜ë“¤ë‹¤.\n",
        "- [ê±°ë¦¬ì¸¡ì • ë°©ì‹](https://datascienceschool.net/view-notebook/094bcb7b86574711a2e8d81f26bce2f5/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCgGkm0Sih6N"
      },
      "source": [
        "### ğŸ“” Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCNTHwbxhMQS"
      },
      "source": [
        "# Hierarchical clustering ì˜ˆì‹œ1 (by.sklearn)\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "cluster = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward')\n",
        "cluster.fit_predict(X)\n",
        "\n",
        "print(cluster.labels_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdj_3hPvhMTn"
      },
      "source": [
        "# Hierarchical clustering ì˜ˆì‹œ2 (ì‹¤ì œ dataë¡œ ì‘ìš©í•˜ëŠ” ë²•)\n",
        "import scipy.cluster.hierarchy as shc\n",
        "data = customer_data.iloc[:, 3:5].values    # iloc ì˜ë¯¸, ì „ì²´ rowì™€ 3~4ë²ˆì§¸ columnì˜ ê°’ì„ nparray í˜•ì‹ìœ¼ë¡œ ë°˜í™˜\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.title(\"Customer Dendograms\")\n",
        "dend = shc.dendrogram(shc.linkage(data, method='ward'))    # dendrogramì—ì„œ ì ì • êµ°ì§‘ ìˆ˜ë¥¼ íŒŒì•…í•˜ê³ \n",
        "\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "cluster = AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward')    # ê·¸ êµ°ì§‘ ìˆ˜ë¥¼ ì ìš©ì‹œì¼œì¤Œ\n",
        "cluster.fit_predict(data)\n",
        "\n",
        "print(cluster.labels_)\n",
        "\n",
        "# scatter plot ê·¸ë¦¬ê¸°\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.scatter(data[:,0], data[:,1], c=cluster.labels_, cmap='rainbow')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ97q4hWhVf0"
      },
      "source": [
        "# Hierarchical clustering ì˜ˆì‹œ3\n",
        "linked = linkage(X, 'single')\n",
        "\n",
        "labelList = range(1, 11)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "dendrogram(linked,\n",
        "            orientation='top',\n",
        "            labels=labelList,\n",
        "            distance_sort='descending',\n",
        "            show_leaf_counts=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvZ5Q-fky4TV"
      },
      "source": [
        "## ğŸ” DBSCAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54bdAN0XkTlT"
      },
      "source": [
        "- Density-Based Spatial Clustering of Applications with Noise  \n",
        ": ë°€ë„ ê¸°ë°˜ì˜ í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ ì ì´ ì„¸ë°€í•˜ê²Œ ëª°ë ¤ ìˆëŠ” ê²ƒì„ ê¸°ì¤€ìœ¼ë¡œ Clusteringì„ í•˜ëŠ” ë°©ë²•  \n",
        ": ì–´ëŠ í•œ ì ì„ ê¸°ì¤€ìœ¼ë¡œ ì¼ì • ë°˜ê²½ ì´ë‚´ì˜ ì ë“¤ì„ í•˜ë‚˜ì˜ Clusterë¡œ ì¸ì‹í•œë‹¤.\n",
        ": perdict() ê¸°ëŠ¥ì´ ì—†ì–´ì„œ ì˜ˆì¸¡ì„ ìœ„í•´ì„œëŠ” `KNeightborsClassifier`ë¥¼ ì‚¬ìš©"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5rEH9sfkThq"
      },
      "source": [
        "<h3> ğŸ“” DBSCAN Algorithm </h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_iUQmFVkTeg"
      },
      "source": [
        "1. í•œ ì  Pë¥¼ ê¸°ì¤€ìœ¼ë¡œ Îµ(eps) ë°˜ê²½ ë‚´ì— ì ì´ ì§€ì •í•œ ê°œìˆ˜(minPts) ì´ìƒì´ ìˆìœ¼ë©´ í•´ë‹¹ ì  Pë¥¼ Core Pointë¼ê³  í•œë‹¤.\n",
        "2. ì•ì˜ ì  Pë¥¼ Core Pointë¡œ í•˜ëŠ” Clusterì— ì†í•˜ëŠ” P'ì¤‘ì—ì„œ Îµ(eps) ë°˜ê²½ ë‚´ì— ì ì´ ì§€ì •í•œ ê°œìˆ˜(minPts)ë³´ë‹¤ ì‘ìœ¼ë©´ Border Pointë¼ê³  í•œë‹¤.\n",
        "3. ì´ ì™¸ì— Îµ(eps) ë°˜ê²½ì„ ë§Œì¡±í•˜ëŠ” ë²”ìœ„ì— ì–´ë– í•œ ì ë„ í¬í•¨í•˜ì§€ ì•ŠëŠ” ì  P\"ì„ Noise Pointë¼ê³  í•œë‹¤.\n",
        "4. Core Pointì™€ Border Pointì™€ ê°™ì´ Îµ(eps) ë°˜ê²½ ë‚´ì— ì„œë¡œì˜ êµ°ì§‘ì— Pointsê°€ ì†í•˜ëŠ” ê²½ìš°ì— í•˜ë‚˜ì˜ Clusterë¡œ í• ë‹¹í•œë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIZd_szrkTbF"
      },
      "source": [
        "<h3> ğŸ“” DBSCANì˜ ì¥ì  </h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNDN0DtHkTXk"
      },
      "source": [
        "1. Cluster ê°œìˆ˜ë¥¼ ì§€ì •í•˜ì§€ ì•Šì•„ë„ ì ì ˆí•œ Clusterë¥¼ ì°¾ì•„ì¤€ë‹¤.\n",
        "2. ë¶ˆíŠ¹ì •í•œ ëª¨ì–‘ ë¶„í¬ë¥¼ Clustering í•  ìˆ˜ ìˆë‹¤. (Density-based)\n",
        "3. Outlierë¥¼ Noise Pointë¡œ ë¶„ë¥˜í•˜ì—¬ Clustering ì„±ëŠ¥ì„ ì¢‹ê²Œ í•œë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE0lkMIZkTUW"
      },
      "source": [
        "<h3> ğŸ“” DBSCANì˜ ë‹¨ì  </h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLGgETwRkTQv"
      },
      "source": [
        "1. ì…ë ¥í•˜ëŠ” parameter ê°’ì— ë”°ë¼, ë‹¤ë¥¸ Clustering ê²°ê³¼ë¥¼ ë³´ì¸ë‹¤. \n",
        "2. ë°ì´í„° íŠ¹ì„±ì„ ëª¨ë¥¼ ê²½ìš°ì— hyper-parameterë¥¼ ì„¤ì •í•˜ê¸° ì–´ë µë‹¤. \n",
        "3. Computational Complexityê°€ Linearithmic Time( O(m log m) )ì„ ë”°ë¥´ëŠ”ë°, eps ê°’ì´ ì»¤ì§ì— ë”°ë¼ Quadratic Time( O(m2) )ì„ ë”°ë¥´ê²Œ ë˜ì–´ ë³µì¡ë„ê°€ ì¦ê°€í•œë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQY9pdvekfpC"
      },
      "source": [
        "<h3> ğŸ“” DBSCAN in Python </h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdKfo5ygkTNH"
      },
      "source": [
        "- scikit-learnì˜ cluster ì„œë¸Œ íŒ¨í‚¤ì§€ëŠ” DBSCAN Clusteringì„ ìœ„í•œ DBSCAN Classë¥¼ ì œê³µí•œë‹¤.\n",
        "``` python\n",
        "DBSCAN (eps=0.5, min_samples=5, metric=â€™euclideanâ€™, metric_params=None, algorithm=â€™autoâ€™, leaf_size=30, p=None, n_jobs=None)\n",
        "```\n",
        "ì£¼ìš” parameter\n",
        " 1. eps: Îµ(epsilon)ìœ¼ë¡œ samples ì‚¬ì´ì˜ maximum distanceë¡œ Core Pointë¥¼ ì§€ì •í•˜ê¸° ìœ„í•œ ìµœëŒ€ ë°˜ê²½. \n",
        " 2. min_samples: Core Pointë¥¼ ê¸°ì¤€ìœ¼ë¡œ eps ë°˜ê²½ ì•ˆì— ì†í•˜ëŠ” samplesì˜ ê°œìˆ˜."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOCan8R9kS93"
      },
      "source": [
        "<h3> ğŸ“” ì£¼ìš” ë©”ì†Œë“œ </h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9Qq6IrzhXTe"
      },
      "source": [
        " 1. .labels_ : sampleì´ ì§€ì •ëœ Clusterë¥¼ í™•ì¸. (labeling ì´ '-1'ë¡œ ëœ ê²ƒì€ ì•Œê³ ë¦¬ì¦˜ì—ì„œ anomalyë¡œ ì§€ì •ëœ ê²ƒì´ë‹¤.) \n",
        " 2. .core_sample_indices_ : core pointë¡œ ì§€ì •ëœ ê²ƒë“¤ì˜ indexë¥¼ í™•ì¸. (len()ìœ¼ë¡œ core points ì´ ê°œìˆ˜ í™•ì¸ ê°€ëŠ¥) \n",
        " 3. .components_ : core pointì˜ ì¢Œí‘œ í™•ì¸."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_1sV2q-iitk"
      },
      "source": [
        "### ğŸ“” Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ohr5DwKohXdN"
      },
      "source": [
        "# DBSCAN ì˜ˆì‹œ\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "X, y = make_moons(n_samples = 1000, noise = .05, random_state = 0)\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "dbscan = DBSCAN(eps = 0.08, min_samples = 5)\n",
        "dbscan.fit(X)\n",
        "\n",
        "np.unique(dbscan.labels_)\n",
        "```\n",
        "# array([-1,  0,  1], dtype=int64)\n",
        "```\n",
        "\n",
        "dbscan.core_sample_indices_[:10]\n",
        "```\n",
        "# array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)\n",
        "```\n",
        "\n",
        "dbscan.components_[:10]\n",
        "```\n",
        "# array([[ 2.02100097,  0.49017924],\n",
        "        [ 1.6782009 , -0.20198687],\n",
        "        [-0.28224484,  0.85878484],\n",
        "        [-0.02143996,  0.17628146],\n",
        "        [ 0.50484202, -0.3910431 ],\n",
        "        [ 1.96953895,  0.36005521],\n",
        "        [ 0.95659588,  0.2536649 ],\n",
        "        [ 0.0948788 ,  0.98337847],\n",
        "        [-0.4416603 ,  0.87203428],\n",
        "        [ 0.70751638, -0.5126737 ]])\n",
        "````\n",
        "\n",
        "## Classifier ì˜ˆì‹œ\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors = 50)\n",
        "knn.fit(dbscan.components_, dbscan.labels_[dbscan.core_sample_indices_])\n",
        "\n",
        "# ìƒˆë¡œìš´ ë°ì´í„° ìƒ˜í”Œì„ ì„ì˜ë¡œ ì„¤ì •\n",
        "X_new = np.array([[-0.5,0], [0,0.5], [1, -0.1], [2,1]])\n",
        "knn.predict(X_new)\n",
        "\n",
        "knn.predict_proba(X_new)\n",
        "```\n",
        "# array([[0.2 , 0.8 ],\n",
        "        [1.  , 0.  ],\n",
        "        [0.18, 0.82],\n",
        "        [1.  , 0.  ]])\n",
        "```\n",
        "\n",
        "core_mask = np.zeros_like(dbscan.labels_, dtype = bool)\n",
        "core_mask[dbscan.core_sample_indices_] = True\n",
        "noise_mask = dbscan.labels_ == -1\n",
        "border_mask = ~(core_mask | noise_mask)\n",
        "\n",
        "cores = dbscan.components_\n",
        "noise = X[noise_mask]\n",
        "border = X[border_mask]\n",
        "\n",
        "plt.scatter(cores[:,0], cores[:,1], s = 10, c = dbscan.labels_[core_mask])\n",
        "plt.scatter(noise[:,0], noise[:,1], c = 'r', marker = 'x', s= 30)\n",
        "plt.scatter(border[:,0], border[:,1], c = 'b', marker = '*', s = 30)\n",
        "\n",
        "plt.title(\"eps = 0.08, min_samples = 5\")\n",
        "\n",
        "# ìƒˆë¡œ ìƒì„±í•œ ë°ì´í„°ë¥¼ ì¶”ê°€\n",
        "plt.scatter(X_new[:,0], X_new[:,1], c= \"k\", marker = \"+\", s = 400, zorder = 999)\n",
        "\n",
        "y_dist, y_pred_idx = knn.kneighbors(X_new, n_neighbors=1)\n",
        "y_pred = dbscan.labels_[dbscan.core_sample_indices_][y_pred_idx]\n",
        "y_pred[y_dist > 0.2] = -1\n",
        "y_pred.ravel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uM2bgz0hbD-"
      },
      "source": [
        "# DBSCANì„ ì ìš©í•œ scatter plot\n",
        "core_mask = np.zeros_like(dbscan.labels_, dtype = bool)\n",
        "core_mask[dbscan.core_sample_indices_] = True\n",
        "noise_mask = dbscan.labels_ == -1\n",
        "border_mask = ~(core_mask | noise_mask)\n",
        "\n",
        "cores = dbscan.components_\n",
        "noise = X[noise_mask]\n",
        "border = X[border_mask]\n",
        "\n",
        "plt.scatter(cores[:,0], cores[:,1], s = 10, c = dbscan.labels_[core_mask])\n",
        "plt.scatter(noise[:,0], noise[:,1], c = 'r', marker = 'x', s= 30)\n",
        "plt.scatter(border[:,0], border[:,1], c = 'b', marker = '*', s = 30)\n",
        "\n",
        "plt.title(\"eps = 0.08, min_samples = 5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p0Lc8RFy4XJ"
      },
      "source": [
        "## ğŸ” Gaussian Mixture model (GMM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlQ8kqj4hchX"
      },
      "source": [
        "- Mixture Modelì´ë€, ì „ì²´ ë¶„í¬ì—ì„œ í•˜ìœ„ ë¶„í¬ê°€ ì¡´ì¬í•œë‹¤ê³  ê°€ì •í•˜ëŠ” ëª¨ë¸ì´ë‹¤.\n",
        "- ë°ì´í„°ê°€ ëª¨ìˆ˜ë¥¼ ê°€ì§€ëŠ” ì—¬ëŸ¬ ê°œì˜ ë¶„í¬ë¡œë¶€í„° í•©ì³ì§„ í˜•íƒœë¼ëŠ” ê²ƒì´ë‹¤.\n",
        "- ì¦‰, Gaussian Mixture Modelì€ í•©ì³ì§„ ì—¬ëŸ¬ ê°œì˜ ë¶„í¬ê°€ Gaussian Distributionì˜ í˜•íƒœì¸ ê²ƒì„ ë§í•œë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BRRcF-8ijaK"
      },
      "source": [
        "### ğŸ“” Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfrtHrMahclu"
      },
      "source": [
        "## GMM ì˜ˆì‹œ\n",
        "# ë¶„í¬ ë§Œë“¤ì–´ì£¼ê¸°\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "dist1 = np.random.normal(-0.5, 0.2, 2000)\n",
        "dist2 = np.random.normal(-0.1, 0.07, 5000)\n",
        "dist3 = np.random.normal(0.2, 0.13, 10000)\n",
        "\n",
        "df1 = pd.DataFrame(dist1)\n",
        "df2 = pd.DataFrame(dist2)\n",
        "df3 = pd.DataFrame(dist3)\n",
        "df_merged = pd.concat([df1, df2, df3], ignore_index = True)\n",
        "\n",
        "df_merged_weights = np.ones_like(df_merged.values)\n",
        "\n",
        "plt.hist(df_merged.values, bins = 80, weights = df_merged_weights, color = 'tomato')\n",
        "\n",
        "plt.xlim(-1.3, 1.0)\n",
        "plt.ylabel('counts')\n",
        "plt.legend(['Merged Distribution'], loc = \"upper left\")\n",
        "plt.show()\n",
        "\n",
        "# GMM ì“°ê¸°\n",
        "from sklearn.mixture import GaussianMixture\n",
        "gmm = GaussianMixture(n_components = 3, n_init = 10)\n",
        "gmm.fit(df_merged)\n",
        "\n",
        "gmm.weights_\n",
        "\n",
        "gmm.means_\n",
        "\n",
        "gmm.covariances_\n",
        "\n",
        "gmm.converged_\n",
        "\n",
        "gmm.n_iter_\n",
        "\n",
        "gmm.predict(df_merged)\n",
        "\n",
        "# GMM ì ìš© í›„ ê²°ê³¼ plotìœ¼ë¡œ ë‚˜íƒ€ë‚´ê¸°\n",
        "import scipy.stats as stats\n",
        "\n",
        "weights = gmm.weights_\n",
        "means = gmm.means_\n",
        "covars = gmm.covariances_\n",
        "\n",
        "# df_mergedë¥¼ dataframeì—ì„œ arrayë¡œ ë³€í™˜\n",
        "arr_merged = df_merged.values.flatten()\n",
        "\n",
        "# ë°ì´í„° ë²”ìœ„ ë° ê°œìˆ˜\n",
        "xx = np.linspace(min(arr_merged),max(arr_merged),17000)\n",
        "\n",
        "pdf_1 = stats.norm(loc = means[0], scale = np.sqrt(covars[0]))\n",
        "pdf_2 = stats.norm(loc = means[1], scale = np.sqrt(covars[1]))\n",
        "pdf_3 = stats.norm(loc = means[2], scale = np.sqrt(covars[2]))\n",
        "\n",
        "n, bins, patches = plt.hist(df_merged.values, bins = 50, normed=True, facecolor='tomato', alpha = .4)\n",
        "plt.plot(xx,weights[0]*pdf_1.pdf(xx)[0], c='green')\n",
        "plt.plot(xx,weights[1]*pdf_2.pdf(xx)[0], c='royalblue')\n",
        "plt.plot(xx,weights[2]*pdf_3.pdf(xx)[0], c='orange')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4GE559ly4Zw"
      },
      "source": [
        "## ğŸ” KNN clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf8mqYXLhfeo"
      },
      "source": [
        "- íŒ¨í„´ ì¸ì‹ì—ì„œ ë¶„ë¥˜ë‚˜ íšŒê·€ì— ì‚¬ìš©ë˜ëŠ” ë¹„ëª¨ìˆ˜ ë°©ì‹ì´ë‹¤. \n",
        "- ë°ì´í„°ì˜ ì§€ì—­ êµ¬ì¡°ì— ë¯¼ê°í•˜ë‹¤. ì‰½ê²Œ êµ¬í˜„ì´ ë˜ë‚˜ ê³„ì‚°ëŸ‰ì´ ë§ë‹¤.\n",
        "- ë§¤ìš° ì¼ê´€ì„± ìˆëŠ” ê²°ê³¼ë¥¼ ë„ì¶œí•´ë‚¸ë‹¤."
      ]
    }
  ]
}